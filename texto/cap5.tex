% Nome do capítulo
\chapter{Experimentos}
% Label para referenciar
\label{cap:5}
% Diminuir espaçamento entre título e texto
\vspace{-1.9cm}

\section{SSD}
\label{secao:5:1}

A primeira implementação consiste em adaptar a \ac{DenseNet} 121 para realizar as tarefas de localização e classificação. Nesse estágio foi feita uma pequena alteração com relação aos modelos propostos por \citeonline{wei-2015} e por \citeonline{cheng-2017}. Enquanto que \citeonline{wei-2015} usou imagens de tamanho $300 \times 300$ e \citeonline{cheng-2017} usou imagens de tamanho $321\times 321$, foi usado nesse trabalho imagens de $311 \times 311$.

O motivo é que, embora a \ac{DenseNet} possua as mesmas características de \textit{downsample} (por meio de convolução ou \textit{pooling}) que a \ac{ResNet}, a implementação da \ac{SSD} por \citeonline{cheng-2017} usa \textit{padding} válido para todas as camadas de \textit{downsample}. Isso faz com que, caso o tamanho de saída da camada de \textit{downsample} não seja inteiro, uma parte seja cortada, podendo causar perda de informação. Sendo assim, foi feita a opção por uma imagem com tamanho menor e o uso de \textit{padding} equivalente, de forma a evitar o corte.

Além dessas modificações, é necessário mudar algumas coisas na arquitetura da rede \ac{DenseNet}121. A primeira delas é que a SSD utiliza ramificações de diferentes níveis para fazer as predições de forma mais precisa. Sendo assim, a primeira alteração é que no segundo bloco de transição é criada uma ramificação fazendo regularização L2. Além disso, a camada de \textit{pooling} do último bloco de transição é substituída por um bloco $3\times3$ com strides igual a 1. Por fim, no final da rede as camadas de \textit{pooling} global e softmax são removidas e essa saída é a segunda ramificação da \ac{SSD}. Depois disso, são adicionados mais dois blocos com camadas de convolução, uma $1\times1$ seguida de um $3\times3$ com \textit{stride} 2. Por fim, mais dois blocos, com as mesmas camadas, porém, as camadas $3\times3$ com \textit{stride} igual a 1.

\subsection{Treinamento}
\label{secao:5:1:1}

A rede foi inicializada com os pesos da \ac{DenseNet}121 treinada na ImageNet, e as camadas adicionais foram inicializadas com o método \textit{He normal} proposto por \citeonline{he-2015}. O algoritmo de treinamento selecionado foi o Adam, proposto por \citeonline{kingma-2014} com os seguintes hiperparâmetros:

\begin{itemize}
	\item $\alpha = 5\times10^{-5}$;
	\item $\beta_1 = 0,9$;
	\item $\beta_2 = 0,999$;
	\item $\epsilon = 1\times10^{-8}$.
\end{itemize}

Além disso, o treinamento ocorreu em um total de 400 épocas, cada época com 1000 iterações e cada iteração com um lote de processamento de 12 imagens. Após 200 épocas de treinamento, a taxa de aprendizado caiu para $5\times10^{-6}$ e após mais 100 épocas, caiu para $5\times10^{-7}$. As bases de dados usadas para os testes foram a \ac{PASCAL VOC} 2007 e 2012. Para treinamento foram usadas as imagens do conjunto de treino e validação de ambas as bases, e para validação dos testes foi utilizada a base de testes de 2007. Os testes serão feitos na base de 2012.

\subsection{Avaliação Qualitativa}
\label{secao:5:1:2}

Depois do treinamento, foram feitos alguns experimentos com imagens aleatórias do conjunto separado para validação para avaliar os resultados obtidos pelo método. Embora o método consiga fazer a detecção e a classificação dos objetos, foram percebidas algumas dificuldades.

\begin{figure}[H]
	% Alterar espaçamentos antes e depois do caption
	\setlength{\abovecaptionskip}{0pt}
	\setlength{\belowcaptionskip}{0pt}
	% Caption
	\caption[Resultado dos testes 1]{Resultado dos testes 1}
	\centering
	\includegraphics[width=.6\textwidth]{imagem/test_image_5.png}
	% Caption centralizada
	\captionsetup{justification=centering}
	\captionfont{\small{\textbf{\\Fonte: Elaborado pelo autor.}}}	
	\label{fig:teste_1}
\end{figure}

Na Figura \ref{fig:teste_1} o modelo detectou a pessoa sentada na cadeira e a cadeira no fundo, porém não detectou o cão deitado no chão. Isso pode refletir um pouco de dificuldade em perceber objetos menores ou que não estejam tão centralizados. Além disso, Embora a pessoa sentada esteja bem nítida na imagem, o modelo não conseguiu ter 100\% de confiança que era uma pessoa.

\begin{figure}[H]
	% Alterar espaçamentos antes e depois do caption
	\setlength{\abovecaptionskip}{0pt}
	\setlength{\belowcaptionskip}{0pt}
	% Caption
	\caption[Resultado dos testes 2]{Resultado dos testes 2}
	\centering
	\includegraphics[width=.6\textwidth]{imagem/test_image_3.png}
	% Caption centralizada
	\captionsetup{justification=centering}
	\captionfont{\small{\textbf{\\Fonte: Elaborado pelo autor.}}}	
	\label{fig:teste_2}
\end{figure}

Na Figura \ref{fig:teste_2} percebemos mais uma vez o problema da confiança baixa. Além disso, a \textit{bounding box} do cão de trás esta pegando apenas a cabeça, sendo que outras partes do corpo dele estão expostas (ainda que sobrepostas parcialmente).


\begin{figure}[H]
	% Alterar espaçamentos antes e depois do caption
	\setlength{\abovecaptionskip}{0pt}
	\setlength{\belowcaptionskip}{0pt}
	% Caption
	\caption[Resultado dos testes 3]{Resultado dos testes 3}
	\centering
	\includegraphics[width=.6\textwidth]{imagem/test_image_1.png}
	% Caption centralizada
	\captionsetup{justification=centering}
	\captionfont{\small{\textbf{\\Fonte: Elaborado pelo autor.}}}	
	\label{fig:teste_3}
\end{figure}

Na Figura \ref{fig:teste_3}, mostra mais uma vez uma nítida dificuldade do modelo em perceber objetos mais distantes. A imagem possui 9 objetos delimitados no \textit{ground-truth} e o modelo conseguiu detectar apenas 2. Ele não consegue perceber nem a mesa de jantar e nem as pessoas mais ao fundo. Além disso, as duas pessoas que estão em pé no canto direito da Figura foram percebidas como apenas uma pelo modelo.


\begin{figure}[H]
	% Alterar espaçamentos antes e depois do caption
	\setlength{\abovecaptionskip}{0pt}
	\setlength{\belowcaptionskip}{0pt}
	% Caption
	\caption[Resultado dos testes 4]{Resultado dos testes 4}
	\centering
	\includegraphics[width=.6\textwidth]{imagem/test_image_2.png}
	% Caption centralizada
	\captionsetup{justification=centering}
	\captionfont{\small{\textbf{\\Fonte: Elaborado pelo autor.}}}	
	\label{fig:teste_4}
\end{figure}

A Figura \ref{fig:teste_4} é bem simples e o único objeto presente está bem nítido, então o modelo consegue percebê-lo com a confiança de 100\%.

\begin{figure}[H]
	% Alterar espaçamentos antes e depois do caption
	\setlength{\abovecaptionskip}{0pt}
	\setlength{\belowcaptionskip}{0pt}
	% Caption
	\caption[Resultado dos testes 5]{Resultado dos testes 5}
	\centering
	\includegraphics[width=.6\textwidth]{imagem/test_image_4.png}
	% Caption centralizada
	\captionsetup{justification=centering}
	\captionfont{\small{\textbf{\\Fonte: Elaborado pelo autor.}}}	
	\label{fig:teste_5}
\end{figure}

Já a Figura \ref{fig:teste_5} mostra um fenômeno diferente: além de detectar o único objeto presente no \textit{ground-truth} com a confiança alta, ele também detecta uma outra instância do mesmo objeto ao fundo. Isso significa que embora o modelo tenha um pouco de dificuldade com objetos que não estão em destaque, essa dificuldade não é tão crítica e existe uma certa robustês.

\subsection{Avaliação Quantitativa}
\label{secao:5:1:3}

Depois dos experimentos, foram feitos os testes para avaliar de forma numérica os resultados do modelo e comparar com o estado da arte. O resultado final apontou um \ac{mAP} de 72,6\%. 

  \begin{table}[H]
    \centering
    \footnotesize
% Alterar espaçamentos antes e depois do caption
    \setlength{\abovecaptionskip}{0pt}
    \setlength{\belowcaptionskip}{0pt}
% Caption
    \caption[Resultados SSD]{Comparação SSD300, SSD321 e SSD311}
    \label{tab:classesNas}
% Conteúdo da tabela
    \begin{tabular}{c|c|c|c}
	Objeto &	SSD311(nosso) & SSD300 & SSD321 \\ 
	\hline 
 	aeroplane & 0,808 & 0,795  & 0,763 \\ 
	bicycle & 0,823 & 0,839  & 0,846  \\ 
	bird & 0,663 & 0,76  & 0,793  \\
	boat & 0,613 & 0,696  & 0,646  \\ 
	bottle & 0,312 & 0,575  & 0,472  \\ 
	bus & 0,828 & 0,87  & 0,854  \\
	car & 0,86 & 0,857  & 0,84  \\ 
	cat & 0,858 & 0,881  & 0,888  \\
	chair & 0,529 & 0,603  & 0,601  \\ 
	cow & 0,75 & 0,815  & 0,826  \\
	diningtable & 0,724 & 0,77  & 0,769  \\ 
	dog & 0,774 & 0,861  & 0,867  \\
	horse & 0,862 & 0,875  & 0,872  \\ 
	motorbike & 0,863 & 0,84  & 0,854  \\
	person & 0,774 & 0,794  & 0,791  \\ 
	pottedplant & 0,426 & 0,523  & 0,508  \\
	sheep & 0,699 & 0,779  & 0,772  \\
	sofa & 0,772 & 0,795  & 0,826  \\
	train & 0,843 & 0,876  & 0,873  \\
	tvmonitor & 0,73 & 0,768  & 0,766  \\ 
	total & 0,726 & 0,775  & 0,771  \\
    \end{tabular}
% Fonte
    \\
    \captionfont{\small{\textbf{\\Fonte: Elaborado pelo autor.}}}
  \end{table}

O resultado evidencia algumas dificuldades que o modelo apresentou conforme visto na seção \ref{secao:5:1:2} e não está no mesmo nível que os resultados obtidos por \citeonline{wei-2015} e \citeonline{cheng-2017}.

Esse problema pode ser justificado por dois fatores principais. Por limitações computacionais, só foi possível fazer o treinamento com 12 imagens por iteração, enquanto que os modelos de \citeonline{wei-2015} e \citeonline{cheng-2017} treinaram com 32 imagens por iteração. Pelo fato do número de imagens por iteração ser menor, foi necessário treinar por mais iterações o que pode acarretar em um segundo problema: \textit{overfitting}, que é quando o modelo começa a aprender os dados específicos ao invés de aprender a fazer a classificação de forma mais generalista.